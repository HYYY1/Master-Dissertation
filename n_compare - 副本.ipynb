{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = \"\"\n",
    "s_length = 0\n",
    "\n",
    "def load_data():\n",
    "    target_stock = pd.read_csv(\"./data/n_\" + stock_name + \".csv\")\n",
    "    target_stock = pd.DataFrame(target_stock)\n",
    "    # 时间点长度\n",
    "    time_stamp = 50\n",
    "    # 划分训练集与验证集\n",
    "    target_stock = target_stock[['Open', 'High', 'Low', 'Close', 'Volume']]  # 'Volume'\n",
    "\n",
    "    # 新增一列正负表示涨跌\n",
    "    close = target_stock['Close'].tolist()\n",
    "    y = []\n",
    "    for i in range(len(target_stock) - 1):\n",
    "        if close[i + 1] >= close[i]:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(-1)\n",
    "    y.append(0)\n",
    "\n",
    "    v4 = []\n",
    "    for i in range(len(target_stock) - time_stamp - 1):\n",
    "        if (y[i + time_stamp - 2] == 1):\n",
    "            v4.append(1)\n",
    "        else:\n",
    "            v4.append(0)\n",
    "    v4.append(0)\n",
    "    target_stock[\"trend\"] = y\n",
    "    # 归一化\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(target_stock)\n",
    "\n",
    "    train = scaled_data[0:s_length + time_stamp]\n",
    "    test = scaled_data[s_length - time_stamp:]\n",
    "    # 训练集\n",
    "    x_train, y_train = [], []\n",
    "    for i in range(len(train) - time_stamp):\n",
    "        train[i + time_stamp - 1][5] = v4[i]\n",
    "        x_train.append(train[i:i + time_stamp])\n",
    "        y_train.append(train[i + time_stamp, 3])\n",
    "\n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "    # 测试集\n",
    "    x_test, y_test = [], []\n",
    "    for i in range(len(test) - time_stamp):\n",
    "        test[i + time_stamp - 1][5] = v4[i + s_length - time_stamp]\n",
    "        x_test.append(test[i:i + time_stamp])\n",
    "        y_test.append(test[i + time_stamp, 3])\n",
    "\n",
    "    x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def transncomp(closing_price, y_valid):\n",
    "    # preprocessing,ues list\n",
    "    y_valid = y_valid.reshape(-1)\n",
    "    closing_price = np.array(closing_price)\n",
    "    closing_price.reshape(-1)\n",
    "\n",
    "    # temp1\n",
    "    y_valid.tolist()\n",
    "    temp1 = []\n",
    "    for i in range(len(y_valid) - 1):\n",
    "        if y_valid[i + 1] >= y_valid[i]:\n",
    "            temp1.append(1)\n",
    "        else:\n",
    "            temp1.append(-1)\n",
    "\n",
    "    # temp2\n",
    "    closing_price.tolist()\n",
    "    temp2 = []\n",
    "    for i in range(len(closing_price) - 1):\n",
    "        if closing_price[i + 1] >= closing_price[i]:\n",
    "            temp2.append(1)\n",
    "        else:\n",
    "            temp2.append(-1)\n",
    "    TP, FN, FP, TN = 0,0,0,0\n",
    "    # compare\n",
    "    for i, j in zip(temp1,temp2):\n",
    "        if i==1 and j==1:\n",
    "            TP += 1\n",
    "        if i==1 and j==-1:\n",
    "            FN += 1\n",
    "        if i==-1 and j==1:\n",
    "            FP += 1\n",
    "        if i==-1 and j==-1:\n",
    "            TN += 1\n",
    "\n",
    "    accuracy=(TP+TN)/(TP+TN+FP+FN)*100\n",
    "    precision=TP/(TP+FP)*100\n",
    "    recall=TP/(TP+FN)*100\n",
    "    F1=2*((precision*recall)/(precision+recall))\n",
    "    auc = roc_auc_score(temp1,temp2)*100\n",
    "    return accuracy,precision,recall,F1,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_ml():\n",
    "    x_train, x_test, y_train, y_test = load_data()\n",
    "\n",
    "    #LSTM\n",
    "    # from tensorflow.keras.models import Sequential\n",
    "    # from tensorflow.keras.layers import LSTM,Dense\n",
    "    # lstm_model = Sequential()\n",
    "    # lstm_model.add(LSTM(units=100, return_sequences=True, input_dim=x_train.shape[-1], input_length=x_train.shape[1]))\n",
    "    # lstm_model.add(LSTM(units=50))\n",
    "    # lstm_model.add(Dense(1))\n",
    "    # lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    # lstm_model.fit(x_train, y_train, epochs=2, batch_size=32, verbose=1,validation_split=0.2)\n",
    "    # lstm_result = lstm_model.predict(x_test)\n",
    "    # acc = transncomp(lstm_result,y_test)\n",
    "\n",
    "\n",
    "    # 数据展平\n",
    "    x_train_new=np.reshape(x_train,(x_train.shape[0],-1))\n",
    "    y_train_new=np.reshape(y_train,(y_train.shape[0]))\n",
    "    x_test_new=np.reshape(x_test,(x_test.shape[0],-1))\n",
    "    y_test_new=np.reshape(y_test,(y_test.shape[0]))\n",
    "\n",
    "    #ARIMA\n",
    "    from statsmodels.tsa.arima_model import ARIMA\n",
    "    model_ARIMA = ARIMA()\n",
    "    model_ARIMA.fit(x_train_new,y_train_new)\n",
    "    ARIMA_result = model_ARIMA.predict(x_test_new)\n",
    "    acc = transncomp(ARIMA_result,y_test_new)\n",
    "\n",
    "    #KNN\n",
    "    # from sklearn import neighbors\n",
    "    # model_KNeighborsRegressor = neighbors.KNeighborsRegressor()\n",
    "    # model_KNeighborsRegressor.fit(x_train_new,y_train_new)\n",
    "    # knn_result = model_KNeighborsRegressor.predict(x_test_new)\n",
    "    # acc = transncomp(knn_result,y_test_new)\n",
    "    \n",
    "    #Random Forest\n",
    "    # from sklearn import ensemble\n",
    "    # model_RandomForestRegressor = ensemble.RandomForestRegressor(n_estimators=1)  \n",
    "    # model_RandomForestRegressor.fit(x_train_new,y_train_new)\n",
    "    # rf_result = model_RandomForestRegressor.predict(x_test_new)\n",
    "    # acc = transncomp(y_test_new,rf_result)\n",
    "\n",
    "    # #SVM\n",
    "    # from sklearn import svm\n",
    "    # model_SVR = svm.SVR()\n",
    "    # model_SVR.fit(x_train_new,y_train_new)\n",
    "    # svm_result = model_SVR.predict(x_test_new)\n",
    "    # acc = transncomp(svm_result,y_test_new)\n",
    "\n",
    "\n",
    "    f = open(\"ARIMA_out.txt\", \"a\")\n",
    "    print(stock_name,\"ARIMA\",file=f)\n",
    "    print(\"Accuracy:%.2f, Precision:%.2f,Recall:%.2f,F1-score:%.2f,AUC:%.2f\"%(acc[0],acc[1],acc[2],acc[3],acc[4]),file=f)\n",
    "    print(\"**\"*30,file=f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google ------------ 2800\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "\nstatsmodels.tsa.arima_model.ARMA and statsmodels.tsa.arima_model.ARIMA have\nbeen removed in favor of statsmodels.tsa.arima.model.ARIMA (note the .\nbetween arima and model) and statsmodels.tsa.SARIMAX.\n\nstatsmodels.tsa.arima.model.ARIMA makes use of the statespace framework and\nis both well tested and maintained. It also offers alternative specialized\nparameter estimators.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_7792/864644851.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0ms_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mcomp_ml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_7792/4229439523.py\u001b[0m in \u001b[0;36mcomp_ml\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#ARIMA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marima_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mARIMA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mmodel_ARIMA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mARIMA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mmodel_ARIMA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_new\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mARIMA_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_ARIMA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\statsmodels\\tsa\\arima_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\statsmodels\\tsa\\arima_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mARIMA_DEPRECATION_ERROR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: \nstatsmodels.tsa.arima_model.ARMA and statsmodels.tsa.arima_model.ARIMA have\nbeen removed in favor of statsmodels.tsa.arima.model.ARIMA (note the .\nbetween arima and model) and statsmodels.tsa.SARIMAX.\n\nstatsmodels.tsa.arima.model.ARIMA makes use of the statespace framework and\nis both well tested and maintained. It also offers alternative specialized\nparameter estimators.\n"
     ]
    }
   ],
   "source": [
    "stock_list = {\"Google\": 2800,\"Amazon\": 3400,\"Apple\": 3400,\"Microsoft\": 3400,  \"Tesla\": 1800}\n",
    "for key, value in stock_list.items():\n",
    "    print(key, \"------------\", value)\n",
    "    stock_name = key\n",
    "    s_length = value\n",
    "    x_train, x_test, y_train, y_test = load_data()\n",
    "    comp_ml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "338aba4271a224d569376385c4ef2ad191ca33f3f4abbd4c7073be9dd1fea0fe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
