{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = \"\"\n",
    "s_length = 0\n",
    "\n",
    "def load_data():\n",
    "    target_stock = pd.read_csv(\"./data/n_\" + stock_name + \".csv\")\n",
    "    target_stock = pd.DataFrame(target_stock)\n",
    "    # 时间点长度\n",
    "    time_stamp = 50\n",
    "    # 划分训练集与验证集\n",
    "    target_stock = target_stock[['Open', 'High', 'Low', 'Close', 'Volume']]  # 'Volume'\n",
    "\n",
    "    # 新增一列正负表示涨跌\n",
    "    close = target_stock['Close'].tolist()\n",
    "    y = []\n",
    "    for i in range(len(target_stock) - 1):\n",
    "        if close[i + 1] >= close[i]:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(-1)\n",
    "    y.append(0)\n",
    "\n",
    "    v4 = []\n",
    "    for i in range(len(target_stock) - time_stamp - 1):\n",
    "        if (y[i + time_stamp - 2] == 1):\n",
    "            v4.append(1)\n",
    "        else:\n",
    "            v4.append(0)\n",
    "    v4.append(0)\n",
    "    target_stock[\"trend\"] = y\n",
    "    # 归一化\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(target_stock)\n",
    "\n",
    "    train = scaled_data[0:s_length + time_stamp]\n",
    "    test = scaled_data[s_length - time_stamp:]\n",
    "    # 训练集\n",
    "    x_train, y_train = [], []\n",
    "    for i in range(len(train) - time_stamp):\n",
    "        train[i + time_stamp - 1][5] = v4[i]\n",
    "        x_train.append(train[i:i + time_stamp])\n",
    "        y_train.append(train[i + time_stamp, 3])\n",
    "\n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "    # 测试集\n",
    "    x_test, y_test = [], []\n",
    "    for i in range(len(test) - time_stamp):\n",
    "        test[i + time_stamp - 1][5] = v4[i + s_length - time_stamp]\n",
    "        x_test.append(test[i:i + time_stamp])\n",
    "        y_test.append(test[i + time_stamp, 3])\n",
    "\n",
    "    x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def transncomp(closing_price, y_valid):\n",
    "    # preprocessing,ues list\n",
    "    y_valid = y_valid.reshape(-1)\n",
    "    closing_price = np.array(closing_price)\n",
    "    closing_price.reshape(-1)\n",
    "\n",
    "    # temp1\n",
    "    y_valid.tolist()\n",
    "    temp1 = []\n",
    "    for i in range(len(y_valid) - 1):\n",
    "        if y_valid[i + 1] >= y_valid[i]:\n",
    "            temp1.append(1)\n",
    "        else:\n",
    "            temp1.append(-1)\n",
    "\n",
    "    # temp2\n",
    "    closing_price.tolist()\n",
    "    temp2 = []\n",
    "    for i in range(len(closing_price) - 1):\n",
    "        if closing_price[i + 1] >= closing_price[i]:\n",
    "            temp2.append(1)\n",
    "        else:\n",
    "            temp2.append(-1)\n",
    "    TP, FN, FP, TN = 0,0,0,0\n",
    "    # compare\n",
    "    for i, j in zip(temp1,temp2):\n",
    "        if i==1 and j==1:\n",
    "            TP += 1\n",
    "        if i==1 and j==-1:\n",
    "            FN += 1\n",
    "        if i==-1 and j==1:\n",
    "            FP += 1\n",
    "        if i==-1 and j==-1:\n",
    "            TN += 1\n",
    "\n",
    "    accuracy=(TP+TN)/(TP+TN+FP+FN)*100\n",
    "    precision=TP/(TP+FP)*100\n",
    "    recall=TP/(TP+FN)*100\n",
    "    F1=2*((precision*recall)/(precision+recall))\n",
    "    auc = roc_auc_score(temp1,temp2)*100\n",
    "    return accuracy,precision,recall,F1,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval():\n",
    "    x_train, x_test, y_train, y_test = load_data()\n",
    "    model = tf.keras.models.load_model(\"AGA_\"+stock_name+\".h5\")\n",
    "    y_pre = model.predict(x_test)\n",
    "    acc = transncomp(y_pre,y_test)\n",
    "    f = open(\"AGA_out.txt\", \"a\")\n",
    "    print(stock_name,file=f)\n",
    "    print(\"Accuracy:%.2f, Precision:%.2f,Recall:%.2f,F1-score:%.2f,AUC:%.2f\"%(acc[0],acc[1],acc[2],acc[3],acc[4]),file=f)\n",
    "    print(\"**\"*30,file=f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft ------------ 3400\n"
     ]
    }
   ],
   "source": [
    "stock_list = {\"Google\": 2800,\"Amazon\": 3400,\"Apple\": 3400,\"Microsoft\": 3400,  \"Tesla\": 1800}\n",
    "# stock_list = {\"Microsoft\": 3400}\n",
    "for key, value in stock_list.items():\n",
    "    print(key, \"------------\", value)\n",
    "    stock_name = key\n",
    "    s_length = value\n",
    "    x_train, x_test, y_train, y_test = load_data()\n",
    "    eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_ml():\n",
    "    x_train, x_test, y_train, y_test = load_data()\n",
    "\n",
    "    #LSTM\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM,Dense\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(units=100, return_sequences=True, input_dim=x_train.shape[-1], input_length=x_train.shape[1]))\n",
    "    lstm_model.add(LSTM(units=50))\n",
    "    lstm_model.add(Dense(1))\n",
    "    lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    lstm_model.fit(x_train, y_train, epochs=2, batch_size=32, verbose=1,validation_split=0.2)\n",
    "    lstm_result = lstm_model.predict(x_test)\n",
    "    acc = transncomp(lstm_result,y_test)\n",
    "\n",
    "\n",
    "    # 数据展平\n",
    "    # x_train_new=np.reshape(x_train,(x_train.shape[0],-1))\n",
    "    # y_train_new=np.reshape(y_train,(y_train.shape[0]))\n",
    "    # x_test_new=np.reshape(x_test,(x_test.shape[0],-1))\n",
    "    # y_test_new=np.reshape(y_test,(y_test.shape[0]))\n",
    "\n",
    "    #KNN\n",
    "    # from sklearn import neighbors\n",
    "    # model_KNeighborsRegressor = neighbors.KNeighborsRegressor()\n",
    "    # model_KNeighborsRegressor.fit(x_train_new,y_train_new)\n",
    "    # knn_result = model_KNeighborsRegressor.predict(x_test_new)\n",
    "    # acc = transncomp(knn_result,y_test_new)\n",
    "    \n",
    "    #Random Forest\n",
    "    # from sklearn import ensemble\n",
    "    # model_RandomForestRegressor = ensemble.RandomForestRegressor(n_estimators=1)  \n",
    "    # model_RandomForestRegressor.fit(x_train_new,y_train_new)\n",
    "    # rf_result = model_RandomForestRegressor.predict(x_test_new)\n",
    "    # acc = transncomp(y_test_new,rf_result)\n",
    "\n",
    "    # #SVM\n",
    "    # from sklearn import svm\n",
    "    # model_SVR = svm.SVR()\n",
    "    # model_SVR.fit(x_train_new,y_train_new)\n",
    "    # svm_result = model_SVR.predict(x_test_new)\n",
    "    # acc = transncomp(svm_result,y_test_new)\n",
    "\n",
    "\n",
    "    f = open(\"LSTM_out.txt\", \"a\")\n",
    "    print(stock_name,\"LSTM\",file=f)\n",
    "    print(\"Accuracy:%.2f, Precision:%.2f,Recall:%.2f,F1-score:%.2f,AUC:%.2f\"%(acc[0],acc[1],acc[2],acc[3],acc[4]),file=f)\n",
    "    print(\"**\"*30,file=f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google ------------ 2800\n",
      "Epoch 1/2\n",
      "70/70 [==============================] - 7s 60ms/step - loss: 0.0333 - val_loss: 0.0042\n",
      "Epoch 2/2\n",
      "70/70 [==============================] - 2s 22ms/step - loss: 3.3360e-04 - val_loss: 0.0031\n",
      "Amazon ------------ 3400\n",
      "Epoch 1/2\n",
      "85/85 [==============================] - 5s 30ms/step - loss: 0.0012 - val_loss: 4.6601e-05\n",
      "Epoch 2/2\n",
      "85/85 [==============================] - 2s 22ms/step - loss: 6.6512e-06 - val_loss: 3.6639e-05\n",
      "Apple ------------ 3400\n",
      "Epoch 1/2\n",
      "85/85 [==============================] - 5s 33ms/step - loss: 0.0113 - val_loss: 0.0055\n",
      "Epoch 2/2\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 6.5372e-05 - val_loss: 0.0054\n",
      "Microsoft ------------ 3400\n",
      "Epoch 1/2\n",
      "85/85 [==============================] - 6s 33ms/step - loss: 0.0098 - val_loss: 5.1905e-05\n",
      "Epoch 2/2\n",
      "85/85 [==============================] - 2s 22ms/step - loss: 3.0940e-04 - val_loss: 6.0666e-05\n",
      "Tesla ------------ 1800\n",
      "Epoch 1/2\n",
      "45/45 [==============================] - 4s 39ms/step - loss: 0.0173 - val_loss: 0.0032\n",
      "Epoch 2/2\n",
      "45/45 [==============================] - 1s 28ms/step - loss: 4.0655e-04 - val_loss: 0.0026\n"
     ]
    }
   ],
   "source": [
    "stock_list = {\"Google\": 2800,\"Amazon\": 3400,\"Apple\": 3400,\"Microsoft\": 3400,  \"Tesla\": 1800}\n",
    "for key, value in stock_list.items():\n",
    "    print(key, \"------------\", value)\n",
    "    stock_name = key\n",
    "    s_length = value\n",
    "    x_train, x_test, y_train, y_test = load_data()\n",
    "    comp_ml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "338aba4271a224d569376385c4ef2ad191ca33f3f4abbd4c7073be9dd1fea0fe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
