{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ------------ 3400\n",
      "85/85 [==============================] - 7s 44ms/step - loss: 0.1503 - val_loss: 0.0867\n",
      "第1代第1个染色体的适应度为0.452429\n",
      "此染色体为： [2, 2, 85, 126, 86, 43, 0.5, 1]\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 6s 35ms/step - loss: 0.0598 - val_loss: 0.0377\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 3s 30ms/step - loss: 0.0249 - val_loss: 0.0230\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.0104 - val_loss: 0.0149\n",
      "第1代第2个染色体的适应度为0.461538\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.4, 3]\n",
      "Epoch 1/2\n",
      "85/85 [==============================] - 7s 43ms/step - loss: 0.1474 - val_loss: 0.0758\n",
      "Epoch 2/2\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0554 - val_loss: 0.0368\n",
      "第1代第3个染色体的适应度为0.442308\n",
      "此染色体为： [2, 2, 112, 77, 95, 72, 0.4, 2]\n",
      "Generation: 1 Most fitted DNA: [  2.   1. 110.  47.  85.   0.   0.   0.] 适应度为： 0.46153846153846156\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 5s 29ms/step - loss: 0.0598 - val_loss: 0.0384\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 2s 21ms/step - loss: 0.0241 - val_loss: 0.0216\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 2s 22ms/step - loss: 0.0098 - val_loss: 0.0130\n",
      "第2代第1个染色体的适应度为0.573887\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.4, 3]\n",
      "85/85 [==============================] - 5s 30ms/step - loss: 0.0620 - val_loss: 0.0392\n",
      "第2代第2个染色体的适应度为0.439271\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.4, 1]\n",
      "85/85 [==============================] - 5s 30ms/step - loss: 0.0583 - val_loss: 0.0354\n",
      "第2代第3个染色体的适应度为0.530364\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.1, 1]\n",
      "Generation: 2 Most fitted DNA: [  2.   1. 110.  47.  85.   0.   0.   0.] 适应度为： 0.5738866396761133\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 5s 29ms/step - loss: 0.0571 - val_loss: 0.0336\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 2s 21ms/step - loss: 0.0237 - val_loss: 0.0285\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 2s 23ms/step - loss: 0.0103 - val_loss: 0.0131\n",
      "第3代第1个染色体的适应度为0.604251\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.5, 3]\n",
      "85/85 [==============================] - 5s 30ms/step - loss: 0.0624 - val_loss: 0.0396\n",
      "第3代第2个染色体的适应度为0.529352\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.4, 1]\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 5s 35ms/step - loss: 0.0622 - val_loss: 0.0372\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 2s 24ms/step - loss: 0.0275 - val_loss: 0.0209\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 2s 21ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "第3代第3个染色体的适应度为0.578947\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.4, 3]\n",
      "Generation: 3 Most fitted DNA: [  2.   1. 110.  47.  85.   0.   0.   0.] 适应度为： 0.604251012145749\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 5s 34ms/step - loss: 0.0601 - val_loss: 0.0402\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 2s 21ms/step - loss: 0.0272 - val_loss: 0.0199\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 2s 21ms/step - loss: 0.0116 - val_loss: 0.0138\n",
      "第4代第1个染色体的适应度为0.472672\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.1, 3]\n",
      "85/85 [==============================] - 7s 32ms/step - loss: 0.0589 - val_loss: 0.0363\n",
      "第4代第2个染色体的适应度为0.585020\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.2, 1]\n",
      "Epoch 1/2\n",
      "85/85 [==============================] - 5s 31ms/step - loss: 0.0637 - val_loss: 0.0409\n",
      "Epoch 2/2\n",
      "85/85 [==============================] - 2s 21ms/step - loss: 0.0288 - val_loss: 0.0284\n",
      "第4代第3个染色体的适应度为0.446356\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.5, 2]\n",
      "Generation: 4 Most fitted DNA: [  2.   1. 110.  47.  85.   0.   0.   0.] 适应度为： 0.5850202429149798\n",
      "Epoch 1/2\n",
      "85/85 [==============================] - 6s 40ms/step - loss: 0.0668 - val_loss: 0.0466\n",
      "Epoch 2/2\n",
      "85/85 [==============================] - 2s 22ms/step - loss: 0.0310 - val_loss: 0.0273\n",
      "第5代第1个染色体的适应度为0.551619\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.2, 2]\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 5s 31ms/step - loss: 0.0574 - val_loss: 0.0349\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 2s 21ms/step - loss: 0.0240 - val_loss: 0.0178\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 2s 27ms/step - loss: 0.0094 - val_loss: 0.0129\n",
      "第5代第2个染色体的适应度为0.448381\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.2, 3]\n",
      "Epoch 1/2\n",
      "85/85 [==============================] - 5s 32ms/step - loss: 0.0625 - val_loss: 0.0409\n",
      "Epoch 2/2\n",
      "85/85 [==============================] - 2s 23ms/step - loss: 0.0292 - val_loss: 0.0213\n",
      "第5代第3个染色体的适应度为0.447368\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.5, 2]\n",
      "Generation: 5 Most fitted DNA: [  2.   1. 110.  47.  85.   0.   0.   0.] 适应度为： 0.5516194331983806\n",
      "85/85 [==============================] - 5s 29ms/step - loss: 0.0508 - val_loss: 0.0303\n",
      "第6代第1个染色体的适应度为0.456478\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.2, 1]\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 5s 30ms/step - loss: 0.0649 - val_loss: 0.0390\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.0290 - val_loss: 0.0223\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 2s 23ms/step - loss: 0.0137 - val_loss: 0.0215\n",
      "第6代第2个染色体的适应度为0.446356\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.2, 3]\n",
      "Epoch 1/2\n",
      "85/85 [==============================] - 5s 30ms/step - loss: 0.0575 - val_loss: 0.0373\n",
      "Epoch 2/2\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.0252 - val_loss: 0.0184\n",
      "第6代第3个染色体的适应度为0.595142\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.3, 2]\n",
      "Generation: 6 Most fitted DNA: [  2.   1. 110.  47.  85.   0.   0.   0.] 适应度为： 0.5951417004048583\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 6s 41ms/step - loss: 0.0782 - val_loss: 0.0456\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 0.0329 - val_loss: 0.0236\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0131 - val_loss: 0.0166\n",
      "第7代第1个染色体的适应度为0.538462\n",
      "此染色体为： [2, 1, 110, 79, 85, 0.1, 3]\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 5s 29ms/step - loss: 0.0578 - val_loss: 0.0372\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 2s 21ms/step - loss: 0.0240 - val_loss: 0.0172\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.0093 - val_loss: 0.0153\n",
      "第7代第2个染色体的适应度为0.458502\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.1, 3]\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 5s 34ms/step - loss: 0.0628 - val_loss: 0.0419\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 2s 22ms/step - loss: 0.0284 - val_loss: 0.0228\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 2s 22ms/step - loss: 0.0133 - val_loss: 0.0132\n",
      "第7代第3个染色体的适应度为0.544534\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.2, 3]\n",
      "Generation: 7 Most fitted DNA: [  2.   1. 110.  47.  85.   0.   0.   0.] 适应度为： 0.5445344129554656\n",
      "85/85 [==============================] - 6s 36ms/step - loss: 0.0753 - val_loss: 0.0419\n",
      "第8代第1个染色体的适应度为0.462551\n",
      "此染色体为： [2, 1, 110, 79, 85, 0.2, 1]\n",
      "85/85 [==============================] - 5s 34ms/step - loss: 0.0580 - val_loss: 0.0387\n",
      "第8代第2个染色体的适应度为0.454453\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.1, 1]\n",
      "85/85 [==============================] - 6s 33ms/step - loss: 0.0585 - val_loss: 0.0382\n",
      "第8代第3个染色体的适应度为0.581984\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.2, 1]\n",
      "Generation: 8 Most fitted DNA: [  2.   1. 110.  47.  85.   0.   0.   0.] 适应度为： 0.5819838056680162\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 7s 46ms/step - loss: 0.0573 - val_loss: 0.0345\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 2s 27ms/step - loss: 0.0220 - val_loss: 0.0175\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 0.0080 - val_loss: 0.0102\n",
      "第9代第1个染色体的适应度为0.605263\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.2, 3]\n",
      "85/85 [==============================] - 7s 42ms/step - loss: 0.0597 - val_loss: 0.0363\n",
      "第9代第2个染色体的适应度为0.544534\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.5, 1]\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 8s 47ms/step - loss: 0.0547 - val_loss: 0.0354\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0224 - val_loss: 0.0173\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 3s 34ms/step - loss: 0.0084 - val_loss: 0.0146\n",
      "第9代第3个染色体的适应度为0.582996\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.1, 3]\n",
      "Generation: 9 Most fitted DNA: [  2.   1. 110.  47.  85.   0.   0.   0.] 适应度为： 0.6052631578947368\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 7s 46ms/step - loss: 0.0590 - val_loss: 0.0418\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0253 - val_loss: 0.0198\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 2s 27ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "第10代第1个染色体的适应度为0.563765\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.2, 3]\n",
      "85/85 [==============================] - 7s 44ms/step - loss: 0.0585 - val_loss: 0.0348\n",
      "第10代第2个染色体的适应度为0.557692\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.3, 1]\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 9s 56ms/step - loss: 0.0546 - val_loss: 0.0337\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 3s 34ms/step - loss: 0.0225 - val_loss: 0.0162\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 3s 36ms/step - loss: 0.0093 - val_loss: 0.0135\n",
      "第10代第3个染色体的适应度为0.530364\n",
      "此染色体为： [2, 1, 110, 47, 85, 0.5, 3]\n",
      "Generation: 10 Most fitted DNA: [  2.   1. 110.  47.  85.   0.   0.   0.] 适应度为： 0.5637651821862348\n",
      "[0, 0.46153846153846156, 0.5738866396761133, 0.604251012145749, 0.5850202429149798, 0.5516194331983806, 0.5951417004048583, 0.5445344129554656, 0.5819838056680162, 0.6052631578947368, 0.5637651821862348]\n",
      "Microsoft ------------ 3400\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 5s 30ms/step - loss: 0.1789 - val_loss: 0.0853\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 1s 18ms/step - loss: 0.0689 - val_loss: 0.0301\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 0.0252 - val_loss: 0.0108\n",
      "第1代第1个染色体的适应度为0.641052\n",
      "此染色体为： [1, 2, 100, 111, 86, 0.5, 3]\n",
      "85/85 [==============================] - 7s 44ms/step - loss: 0.1833 - val_loss: 0.0879\n",
      "第1代第2个染色体的适应度为0.436805\n",
      "此染色体为： [2, 2, 85, 113, 92, 121, 0.3, 1]\n",
      "85/85 [==============================] - 11s 64ms/step - loss: 0.1028 - val_loss: 0.0615\n",
      "第1代第3个染色体的适应度为0.509606\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.5, 1]\n",
      "Generation: 1 Most fitted DNA: [  1.   2. 100. 111.  86.   0.   0.   0.] 适应度为： 0.641051567239636\n",
      "Epoch 1/2\n",
      "85/85 [==============================] - 3s 22ms/step - loss: 0.1955 - val_loss: 0.1142\n",
      "Epoch 2/2\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 0.0975 - val_loss: 0.0565\n",
      "第2代第1个染色体的适应度为0.417594\n",
      "此染色体为： [1, 2, 100, 111, 86, 0.1, 2]\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 7s 41ms/step - loss: 0.1476 - val_loss: 0.0776\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 0.0641 - val_loss: 0.0323\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 2s 19ms/step - loss: 0.0272 - val_loss: 0.0141\n",
      "第2代第2个染色体的适应度为0.630940\n",
      "此染色体为： [1, 2, 100, 111, 37, 0.1, 3]\n",
      "Epoch 1/2\n",
      "85/85 [==============================] - 9s 37ms/step - loss: 0.0963 - val_loss: 0.0528\n",
      "Epoch 2/2\n",
      "85/85 [==============================] - 2s 26ms/step - loss: 0.0455 - val_loss: 0.0248\n",
      "第2代第3个染色体的适应度为0.456016\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.2, 2]\n",
      "Generation: 2 Most fitted DNA: [  1.   2. 100. 111.  37.   0.   0.   0.] 适应度为： 0.6309403437815976\n",
      "85/85 [==============================] - 4s 24ms/step - loss: 0.1887 - val_loss: 0.1091\n",
      "第3代第1个染色体的适应度为0.554095\n",
      "此染色体为： [1, 2, 100, 111, 86, 0.2, 1]\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 3s 22ms/step - loss: 0.1981 - val_loss: 0.1166\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 0.1006 - val_loss: 0.0585\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 0.0508 - val_loss: 0.0295\n",
      "第3代第2个染色体的适应度为0.626896\n",
      "此染色体为： [1, 2, 100, 111, 86, 0.4, 3]\n",
      "85/85 [==============================] - 8s 41ms/step - loss: 0.1048 - val_loss: 0.0572\n",
      "第3代第3个染色体的适应度为0.416582\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.4, 1]\n",
      "Generation: 3 Most fitted DNA: [  1.   2. 100. 111.  86.   0.   0.   0.] 适应度为： 0.6268958543983822\n",
      "Epoch 1/2\n",
      "85/85 [==============================] - 8s 39ms/step - loss: 0.1048 - val_loss: 0.0591\n",
      "Epoch 2/2\n",
      "85/85 [==============================] - 2s 27ms/step - loss: 0.0517 - val_loss: 0.0318\n",
      "第4代第1个染色体的适应度为0.499494\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.1, 2]\n",
      "85/85 [==============================] - 12s 58ms/step - loss: 0.0945 - val_loss: 0.0524\n",
      "第4代第2个染色体的适应度为0.435794\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.5, 1]\n",
      "85/85 [==============================] - 8s 37ms/step - loss: 0.1031 - val_loss: 0.0604\n",
      "第4代第3个染色体的适应度为0.417594\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.4, 1]\n",
      "Generation: 4 Most fitted DNA: [  2.   2.  42. 124.  37.  48.   0.   0.] 适应度为： 0.4994944388270981\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 9s 45ms/step - loss: 0.0925 - val_loss: 0.0493\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0427 - val_loss: 0.0222\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0195 - val_loss: 0.0109\n",
      "第5代第1个染色体的适应度为0.424671\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.3, 3]\n",
      "Epoch 1/2\n",
      "85/85 [==============================] - 11s 68ms/step - loss: 0.1014 - val_loss: 0.0587\n",
      "Epoch 2/2\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0518 - val_loss: 0.0315\n",
      "第5代第2个染色体的适应度为0.414560\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.2, 2]\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 7s 41ms/step - loss: 0.0960 - val_loss: 0.0543\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 3s 31ms/step - loss: 0.0471 - val_loss: 0.0262\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0234 - val_loss: 0.0131\n",
      "第5代第3个染色体的适应度为0.417594\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.3, 3]\n",
      "Generation: 5 Most fitted DNA: [  2.   2.  42. 124.  37.  48.   0.   0.] 适应度为： 0.4246713852376138\n",
      "85/85 [==============================] - 7s 44ms/step - loss: 0.0958 - val_loss: 0.0539\n",
      "第6代第1个染色体的适应度为0.518706\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.4, 1]\n",
      "Epoch 1/2\n",
      "85/85 [==============================] - 8s 40ms/step - loss: 0.0981 - val_loss: 0.0553\n",
      "Epoch 2/2\n",
      "85/85 [==============================] - 2s 27ms/step - loss: 0.0494 - val_loss: 0.0274\n",
      "第6代第2个染色体的适应度为0.413549\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.4, 2]\n",
      "Epoch 1/2\n",
      "85/85 [==============================] - 12s 40ms/step - loss: 0.1021 - val_loss: 0.0575\n",
      "Epoch 2/2\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0519 - val_loss: 0.0308\n",
      "第6代第3个染色体的适应度为0.567240\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.5, 2]\n",
      "Generation: 6 Most fitted DNA: [  2.   2.  42. 124.  37.  48.   0.   0.] 适应度为： 0.5672396359959555\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 8s 38ms/step - loss: 0.0961 - val_loss: 0.0540\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 3s 31ms/step - loss: 0.0486 - val_loss: 0.0275\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 3s 38ms/step - loss: 0.0254 - val_loss: 0.0144\n",
      "第7代第1个染色体的适应度为0.415571\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.5, 3]\n",
      "Epoch 1/2\n",
      "85/85 [==============================] - 7s 39ms/step - loss: 0.1044 - val_loss: 0.0572\n",
      "Epoch 2/2\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0509 - val_loss: 0.0294\n",
      "第7代第2个染色体的适应度为0.546006\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.4, 2]\n",
      "Epoch 1/2\n",
      "85/85 [==============================] - 9s 50ms/step - loss: 0.1024 - val_loss: 0.0588\n",
      "Epoch 2/2\n",
      "85/85 [==============================] - 3s 35ms/step - loss: 0.0525 - val_loss: 0.0316\n",
      "第7代第3个染色体的适应度为0.416582\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.4, 2]\n",
      "Generation: 7 Most fitted DNA: [  2.   2.  42. 124.  37.  48.   0.   0.] 适应度为： 0.5460060667340748\n",
      "85/85 [==============================] - 7s 42ms/step - loss: 0.0940 - val_loss: 0.0507\n",
      "第8代第1个染色体的适应度为0.449949\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.2, 1]\n",
      "85/85 [==============================] - 9s 41ms/step - loss: 0.0982 - val_loss: 0.0536\n",
      "第8代第2个染色体的适应度为0.427705\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.3, 1]\n",
      "85/85 [==============================] - 8s 49ms/step - loss: 0.0959 - val_loss: 0.0529A: 0s - loss: 0\n",
      "第8代第3个染色体的适应度为0.449949\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.1, 1]\n",
      "Generation: 8 Most fitted DNA: [  2.   2.  42. 124.  37.  48.   0.   0.] 适应度为： 0.4499494438827098\n",
      "85/85 [==============================] - 10s 60ms/step - loss: 0.1078 - val_loss: 0.0654\n",
      "第9代第1个染色体的适应度为0.399393\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.3, 1]\n",
      "85/85 [==============================] - 8s 50ms/step - loss: 0.1083 - val_loss: 0.0634\n",
      "第9代第2个染色体的适应度为0.423660\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.5, 1]\n",
      "85/85 [==============================] - 8s 44ms/step - loss: 0.0994 - val_loss: 0.0563\n",
      "第9代第3个染色体的适应度为0.406471\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.2, 1]\n",
      "Generation: 9 Most fitted DNA: [  2.   2.  42. 124.  37.  48.   0.   0.] 适应度为： 0.4236602628918099\n",
      "Epoch 1/3\n",
      "85/85 [==============================] - 7s 45ms/step - loss: 0.0985 - val_loss: 0.0568\n",
      "Epoch 2/3\n",
      "85/85 [==============================] - 3s 30ms/step - loss: 0.0504 - val_loss: 0.0286\n",
      "Epoch 3/3\n",
      "85/85 [==============================] - 3s 30ms/step - loss: 0.0267 - val_loss: 0.0152\n",
      "第10代第1个染色体的适应度为0.415571\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.5, 3]\n",
      "Epoch 1/2\n",
      "85/85 [==============================] - 11s 56ms/step - loss: 0.1009 - val_loss: 0.0557\n",
      "Epoch 2/2\n",
      "85/85 [==============================] - 3s 38ms/step - loss: 0.0479 - val_loss: 0.0269\n",
      "第10代第2个染色体的适应度为0.485339\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.1, 2]\n",
      "85/85 [==============================] - 7s 39ms/step - loss: 0.1005 - val_loss: 0.0574\n",
      "第10代第3个染色体的适应度为0.550051\n",
      "此染色体为： [2, 2, 42, 124, 37, 48, 0.3, 1]\n",
      "Generation: 10 Most fitted DNA: [  2.   2.  42. 124.  37.  48.   0.   0.] 适应度为： 0.5500505561172901\n",
      "[0, 0.641051567239636, 0.6309403437815976, 0.6268958543983822, 0.4994944388270981, 0.4246713852376138, 0.5672396359959555, 0.5460060667340748, 0.4499494438827098, 0.4236602628918099, 0.5500505561172901]\n",
      "Google ------------ 2800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_6148/4060900345.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[0ms_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m     \u001b[0mgo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_6148/4060900345.py\u001b[0m in \u001b[0;36mgo\u001b[1;34m()\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mpop_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m             \u001b[0mfitness\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_fitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m             \u001b[1;31m# 输出结果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'第%d代第%d个染色体的适应度为%f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0meach_generation\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitness\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_6148/4060900345.py\u001b[0m in \u001b[0;36mget_fitness\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;31m# 定义适用度函数，即aim_function函数，接收返回值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_fitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0maim_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_6148/4060900345.py\u001b[0m in \u001b[0;36maim_function\u001b[1;34m(x_train, y_train, x_test, y_test, num)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;31m# print(\"训练集形状\", x_train.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m     \u001b[1;31m# 验证模型,model.evaluate返回的值是一个数组，其中score[0]为loss,score[1]为准确度\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    869\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 725\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    726\u001b[0m             *args, **kwds))\n\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2969\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2970\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    964\u001b[0m           \u001b[1;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m           \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m             return autograph.converted_call(\n\u001b[0m\u001b[0;32m    967\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    477\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    796\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m    797\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1257\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1258\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1259\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2728\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2729\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2730\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2732\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3415\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3416\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3417\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3419\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    665\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    479\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    789\u001b[0m         \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    755\u001b[0m       loss = self.compiled_loss(\n\u001b[0;32m    756\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n\u001b[1;32m--> 757\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m     \"\"\"\n\u001b[1;32m--> 496\u001b[1;33m     grads_and_vars = self._compute_gradients(\n\u001b[0m\u001b[0;32m    497\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0;32m    498\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    546\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/gradients\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m       \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m     self._assert_valid_dtypes([\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    439\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[1;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1078\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1081\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_backward_function\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    805\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_backward_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[0mcall_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rewrite_forward_and_call_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_backward_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_rewrite_forward_and_call_backward\u001b[1;34m(self, op, *doutputs)\u001b[0m\n\u001b[0;32m    720\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_rewrite_forward_and_call_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mdoutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;34m\"\"\"Add outputs to the forward call and feed them to the grad function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m     \u001b[0mforward_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackwards_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbackwards_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mbackwards_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructured_outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mforward_backward\u001b[1;34m(self, num_doutputs)\u001b[0m\n\u001b[0;32m    629\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mforward_backward\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m     \u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_forward_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_construct_forward_backward\u001b[1;34m(self, num_doutputs)\u001b[0m\n\u001b[0;32m    672\u001b[0m       backwards_graph = func_graph_module.FuncGraph(\n\u001b[0;32m    673\u001b[0m           _backward_name(self._func_graph.name))\n\u001b[1;32m--> 674\u001b[1;33m       func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m    675\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbackwards_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m           \u001b[0mpython_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_backprop_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_backprop_function\u001b[1;34m(*grad_ys)\u001b[0m\n\u001b[0;32m    663\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_backprop_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 665\u001b[1;33m         return gradients_util._GradientsHelper(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    666\u001b[0m             \u001b[0mtrainable_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    681\u001b[0m                 \u001b[1;31m# If grad_fn was found, do not use SymbolicGradient even for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0m\u001b[0;32m    684\u001b[0m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0;32m    685\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Exit early\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m   \u001b[1;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    682\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 684\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    685\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py\u001b[0m in \u001b[0;36m_TransposeGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    808\u001b[0m   \u001b[1;34m\"\"\"Returns unshuffle(grad).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m   \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvert_permutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36minvert_permutation\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m   4365\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4366\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4367\u001b[1;33m     _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[0;32m   4368\u001b[0m         \"InvertPermutation\", x=x, name=name)\n\u001b[0;32m   4369\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    746\u001b[0m       \u001b[1;31m# Add Op to graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[0;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    588\u001b[0m       \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         compute_device)\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3526\u001b[0m     \u001b[1;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3527\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3528\u001b[1;33m       ret = Operation(\n\u001b[0m\u001b[0;32m   3529\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3530\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2013\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2015\u001b[1;33m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[0;32m   2016\u001b[0m                                 control_input_ops, op_def)\n\u001b[0;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(987)\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras import optimizers, losses, metrics, models\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "\n",
    "# 不显示警告信息\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "stock_list = {\"Apple\":3400,\"Microsoft\":3400,\"Google\":2800,\"Tesla\":1800}\n",
    "\n",
    "best_model_result = 0\n",
    "best_gene = []  # 初始化一个保存最优参数组合的列表\n",
    "stock_name = \"\"\n",
    "s_length = 0\n",
    "\n",
    "def load_data():\n",
    "    target_stock = pd.read_csv(\"n_\"+stock_name+\".csv\")\n",
    "    target_stock = pd.DataFrame(target_stock)\n",
    "    # 时间点长度\n",
    "    time_stamp = 50\n",
    "    # 划分训练集与验证集\n",
    "    target_stock = target_stock[['Open', 'High', 'Low', 'Close', 'Volume']]  # 'Volume'\n",
    "\n",
    "    # 新增一列正负表示涨跌\n",
    "    close = target_stock['Close'].tolist()\n",
    "    y = []\n",
    "    for i in range(len(target_stock) - 1):\n",
    "        if close[i + 1] >= close[i]:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(-1)\n",
    "    y.append(0)\n",
    "\n",
    "    v4 = []\n",
    "    for i in range(len(target_stock) - time_stamp - 1):\n",
    "        if (y[i + time_stamp - 2] == 1):\n",
    "            v4.append(1)\n",
    "        else:\n",
    "            v4.append(0)\n",
    "    v4.append(0)\n",
    "    target_stock[\"trend\"] = y\n",
    "    # 归一化\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(target_stock)\n",
    "    \n",
    "    train = scaled_data[0:s_length + time_stamp]\n",
    "    test = scaled_data[s_length - time_stamp:]\n",
    "    # 训练集\n",
    "    x_train, y_train = [], []\n",
    "    for i in range(len(train) - time_stamp):\n",
    "        train[i + time_stamp - 1][5] = v4[i]\n",
    "        x_train.append(train[i:i + time_stamp])\n",
    "        y_train.append(train[i + time_stamp, 3])\n",
    "\n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "    # 测试集\n",
    "    x_test, y_test = [], []\n",
    "    for i in range(len(test) - time_stamp):\n",
    "        test[i + time_stamp - 1][5] = v4[i + s_length - time_stamp]\n",
    "        x_test.append(test[i:i + time_stamp])\n",
    "        y_test.append(test[i + time_stamp, 3])\n",
    "\n",
    "    x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def transncomp(closing_price, y_valid):\n",
    "    # preprocessing,ues list\n",
    "    y_valid = y_valid.reshape(-1)\n",
    "    closing_price = np.array(closing_price)\n",
    "    closing_price.reshape(-1)\n",
    "\n",
    "    # temp1\n",
    "    y_valid.tolist()\n",
    "    temp1 = []\n",
    "    for i in range(len(y_valid) - 1):\n",
    "        if y_valid[i + 1] >= y_valid[i]:\n",
    "            temp1.append(1)\n",
    "        else:\n",
    "            temp1.append(-1)\n",
    "\n",
    "    # temp2\n",
    "    closing_price.tolist()\n",
    "    temp2 = []\n",
    "    for i in range(len(closing_price) - 1):\n",
    "        if closing_price[i + 1] >= y_valid[i]:\n",
    "            temp2.append(1)\n",
    "        else:\n",
    "            temp2.append(-1)\n",
    "\n",
    "    # compare\n",
    "    sum = 0\n",
    "    for i, j in zip(temp1, temp2):\n",
    "        if i == j:\n",
    "            sum += 1\n",
    "    acc = sum / len(y_valid)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def lstm_mode(inputs, units_num, sequences_state):\n",
    "    # input主要是用来定义lstm的输入，input的一般是在第一层lstm层之前，units_num即是隐藏层神经元个数，sequence_state即是lstm层输出的方式\n",
    "    lstm = LSTM(units_num, return_sequences=sequences_state)(inputs)\n",
    "    # print(\"lstm:\", lstm.shape)\n",
    "    return lstm\n",
    "\n",
    "\n",
    "# 定义全连接层、BN层\n",
    "def dense_mode(input, dropout, units_num):\n",
    "    # 这里主要定义全连接层的输入，input参数定义dense的第一次输入，units_num代表隐藏层神经元个数\n",
    "    # 这里定义全连接层，采用L2正则化来防止过拟合，激活函数为relu\n",
    "    dense = Dense(units_num, kernel_regularizer=tf.keras.regularizers.l2(0.001), activation='tanh')(input)\n",
    "    # print(\"dense：\", dense.shape)\n",
    "    # 定义dropout层，概率为0.2\n",
    "    drop_out = Dropout(rate=dropout)(dense)\n",
    "    # 定义BN层，可以理解为是隐藏层的标准化过程\n",
    "    # dense_bn = BatchNormalization()(drop_out)\n",
    "    return dense, drop_out\n",
    "\n",
    "\n",
    "# 这里定义的即是评价lstm效果的函数——也是遗传算法的适应度函数\n",
    "def aim_function(x_train, y_train, x_test, y_test, num):\n",
    "    # 这里传入数据和参数数组num,num保存了需要优化的参数\n",
    "    # 这里我们设置num数组中num[0]代表lstm的层数。\n",
    "    global best_model_result\n",
    "    lstm_layers = num[0]\n",
    "    # num[2:2 + lstm_layers]分别为lstm各层的神经元个数，num(1)为全连接层的层数)\n",
    "    lstm_units = num[2:2 + lstm_layers]\n",
    "    # 将num\n",
    "    lstm_name = list(np.zeros((lstm_layers,)))\n",
    "    # 设置全连接层的参数\n",
    "    # num(1)为全连接的参数\n",
    "    lstm_dense_layers = num[1]\n",
    "    # 将lstm层之后的地方作为全连接层各层的参数\n",
    "    lstm_dense_units = num[2 + lstm_layers: 2 + lstm_layers + lstm_dense_layers]\n",
    "    #\n",
    "    lstm_dense_name = list(np.zeros((lstm_dense_layers,)))\n",
    "    lstm_dense_dropout_name = list(np.zeros((lstm_dense_layers,)))\n",
    "\n",
    "    dropout = num[2 + lstm_layers + lstm_dense_layers]\n",
    "    epochs = int(num[2 + lstm_layers + lstm_dense_layers + 1])\n",
    "\n",
    "    # 这主要是定义lstm的第一层输入，形状为训练集数据的形状\n",
    "    inputs_lstm = Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "\n",
    "    # 这里定义lstm层的输入（如果为第一层lstm层，则将初始化的input输入，如果不是第一层，则接受上一层输出的结果）\n",
    "    for i in range(lstm_layers):\n",
    "        if i == 0:\n",
    "            inputs = inputs_lstm\n",
    "        else:\n",
    "            inputs = lstm_name[i - 1]\n",
    "        if i == lstm_layers - 1:\n",
    "            sequences_state = False\n",
    "        else:\n",
    "            sequences_state = True\n",
    "        # 通过循环，我们将每层lstm的参数都设计完成\n",
    "        lstm_name[i] = lstm_mode(inputs, lstm_units[i], sequences_state=sequences_state)\n",
    "\n",
    "    # 同理设计全连接层神经网络的参数\n",
    "    for i in range(lstm_dense_layers):\n",
    "        if i == 0:\n",
    "            inputs = lstm_name[lstm_layers - 1]\n",
    "        else:\n",
    "            inputs = lstm_dense_name[i - 1]\n",
    "        lstm_dense_name[i], lstm_dense_dropout_name[i] = dense_mode(inputs, dropout, units_num=lstm_dense_units[i])\n",
    "\n",
    "    outputs_lstm = Dense(1)(lstm_dense_dropout_name[lstm_dense_layers - 1])\n",
    "    # print(\"last_dense\", outputs_lstm.shape)\n",
    "    # 利用函数式调试神经网络，调用inputs和outputs之间的神经网络\n",
    "    LSTM_model = tf.keras.Model(inputs=inputs_lstm, outputs=outputs_lstm)\n",
    "    LSTM_model.compile(optimizer=optimizers.Adam(), loss='mean_squared_error', )\n",
    "    # print(\"训练集形状\", x_train.shape)\n",
    "\n",
    "    history = LSTM_model.fit(x_train, y_train, batch_size=32, epochs=epochs, validation_split=0.2, verbose=1)\n",
    "    # 验证模型,model.evaluate返回的值是一个数组，其中score[0]为loss,score[1]为准确度\n",
    "\n",
    "    # 反归一化\n",
    "    # scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    # scaler.fit_transform(pd.DataFrame(test['Close'].values))\n",
    "    closing_price = LSTM_model.predict(x_test)\n",
    "    \n",
    "    # closing_price = scaler.inverse_transform(closing_price)\n",
    "    # y_valid = scaler.inverse_transform([y_test])\n",
    "    # acc\n",
    "    acc = transncomp(closing_price, y_test)\n",
    "\n",
    "    # 保存最优模型，并用最优模型的参数设置代替下一代最弱参数\n",
    "    if acc > best_model_result:\n",
    "        best_model_result = acc\n",
    "        LSTM_model.save(\"GA_\"+stock_name+'.h5')\n",
    "\n",
    "    # 原始的并没有保存模型\n",
    "    return acc\n",
    "\n",
    "\n",
    "# 设置遗传算法的参数\n",
    "DNA_size = 2\n",
    "DNA_size_max = 8  # 每条染色体的长度\n",
    "POP_size = 3  # 种群数量\n",
    "CROSS_RATE = 0.5  # 交叉率\n",
    "MUTATION_RATE = 0.01  # 变异率\n",
    "N_GENERATIONS = 10  # 迭代次数\n",
    "\n",
    "Pc1 = 0.9  # 自适应交叉概率1\n",
    "Pc2 = 0.6  # 自适应交叉概率2\n",
    "Pm1 = 0.1  # 自适应变异概率1\n",
    "Pm2 = 0.5  # 自适应变异概率2\n",
    "\n",
    "\n",
    "# 定义适用度函数，即aim_function函数，接收返回值\n",
    "def get_fitness(x):\n",
    "    return aim_function(x_train, y_train, x_test, y_test, num=x)\n",
    "\n",
    "\n",
    "# 生成新的种群\n",
    "def select(pop, fitness):\n",
    "    # 这里主要是进行选择操作，即从20个种群中随机选取重复随机采样出20个种群进行种群初始化操作，p代表被选择的概率，这里采用的是轮盘赌的方式\n",
    "    idx = np.random.choice(np.arange(POP_size), size=POP_size, replace=True, p=fitness / fitness.sum())\n",
    "    # 将选择的种群组成初始种群pop\n",
    "    return pop[idx]\n",
    "\n",
    "\n",
    "# 交叉函数\n",
    "def crossover(parent, pop):\n",
    "    # 这里主要进行交叉操作，随机数小于交叉概率则发生交叉\n",
    "    if np.random.rand() < CROSS_RATE:\n",
    "        # 从20个种群中选择一个种群进行交叉\n",
    "        i_ = np.random.randint(0, POP_size, size=1)  # 染色体的序号\n",
    "        # 这里将生成一个8维的2进制数，并转换层成bool类型，true表示该位置交叉，False表示不交叉\n",
    "        cross_points = np.random.randint(0, 2, size=DNA_size_max).astype(np.bool)  # 用True、False表示是否置换\n",
    "\n",
    "        # 这一部分主要是对针对不做变异的部分\n",
    "        for i, point in enumerate(cross_points):\n",
    "            '''\n",
    "            第一部分：这里是指该位点为神经元个数的位点，本来该交换，但其中位点为0,末尾的0位置就\n",
    "            不应该交叉，因为交叉完后,会对前两位的参数产生影响。\n",
    "\n",
    "            第二部分：即对前两位不进行交叉操作，因为前两位代表的是层数，层数交叉后会对神经元的个数产生影响\n",
    "            '''\n",
    "            # 第一部分\n",
    "            if point == True and pop[i_, i] * parent[i] == 0:\n",
    "                cross_points[i] = False\n",
    "            # 第二部分\n",
    "            if point == True and i < 2:\n",
    "                cross_points[i] = False\n",
    "        # 将第i_条染色体上对应位置的基因置换到parent染色体上\n",
    "        parent[cross_points] = pop[i_, cross_points]\n",
    "    return parent\n",
    "\n",
    "\n",
    "# 定义变异函数\n",
    "def mutate(child):\n",
    "    # mutate - k2 = 0.5 k4 = 0.5\n",
    "\n",
    "    # 变异操作也只是针对后6位参数\n",
    "    for point in range(DNA_size_max):\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            # 2位参数之后的参数才参与变异\n",
    "            if (point >= 2) and (point < len(child) - 2):\n",
    "                if child[point] != 0:\n",
    "                    child[point] = np.random.randint(32, 128)\n",
    "            if point == len(child) - 2:\n",
    "                child[point] = np.random.randint(1, 5) / 10\n",
    "            if point == len(child) - 1:\n",
    "                child[point] = np.random.randint(1, 3)\n",
    "    return child\n",
    "\n",
    "def go():\n",
    "    global best_model_result\n",
    "    global best_gene\n",
    "    best_model_result = 0\n",
    "    best_gene = []  # 初始化一个保存最优参数组合的列表\n",
    "    # 在数组中保存每轮最优，输出数据\n",
    "    best = []\n",
    "    best.append(0)\n",
    "    pop_pop = [] # 记录一个列表保存参数和适应度 画热力图\n",
    "    # 初始化2列层数参数\n",
    "    pop_layers = np.zeros((POP_size, DNA_size), np.int32)\n",
    "    pop_layers[:, 0] = np.random.randint(1, 3, size=(POP_size,))  # change 4\n",
    "    pop_layers[:, 1] = np.random.randint(1, 3, size=(POP_size,))\n",
    "\n",
    "    # 种群\n",
    "    # 初始化20x8的种群\n",
    "    pop = np.zeros((POP_size, DNA_size_max))\n",
    "    # 将初始化的种群赋值，前两列为层数参数，后6列为神经元个数参数\n",
    "    for i in range(POP_size):\n",
    "        # 随机从[32,256]中抽取随机数组组成神经元个数信息\n",
    "        pop_neurons = np.random.randint(32, 128, size=(pop_layers[i].sum(),))\n",
    "        # 将2列层数信息和6列神经元个数信息合并乘8维种群信息\n",
    "        pop_stack = np.hstack((pop_layers[i], pop_neurons))\n",
    "        # 将这些信息赋值给pop种群进行初始化种群\n",
    "        for j, gene in enumerate(pop_stack):\n",
    "            pop[i][j] = gene\n",
    "\n",
    "    # 在迭代次数内，计算种群的适应度函数\n",
    "    for each_generation in range(N_GENERATIONS):\n",
    "        # 初始化适应度\n",
    "        fitness = np.zeros([POP_size, ])\n",
    "        # 遍历20个种群，对基因进行操作\n",
    "        for i in range(POP_size):\n",
    "            # 第i个染色体上的基因\n",
    "            pop_list = list(pop[i])\n",
    "            pop_copy = np.array(pop_list).copy()\n",
    "            # 对赋值为0的基因进行删除\n",
    "            for j, each in enumerate(pop_list):\n",
    "                if each == 0.0:\n",
    "                    index = j\n",
    "                    pop_list = pop_list[:j]\n",
    "            # 将基因进行转换为int类型\n",
    "            for k, each in enumerate(pop_list):\n",
    "                each_int = int(each)\n",
    "                pop_list[k] = each_int\n",
    "            # 将计算出来的适应度填写在适应度数组中\n",
    "\n",
    "            # test1 add dropout and epochs\n",
    "            pop_list.append(random.randint(1, 5) / 10)\n",
    "            pop_list.append(random.randint(1, 3))\n",
    "\n",
    "            fitness[i] = get_fitness(pop_list)\n",
    "            # 输出结果\n",
    "            print('第%d代第%d个染色体的适应度为%f' % (each_generation + 1, i + 1, fitness[i]))\n",
    "            print('此染色体为：', pop_list)\n",
    "            pop_copy = pop_copy.tolist()\n",
    "            pop_copy.append(fitness[i])\n",
    "            pop_pop.append(pop_copy)\n",
    "\n",
    "        # 创建最优模型\n",
    "        print('Generation:', each_generation + 1, 'Most fitted DNA:', pop[np.argmax(fitness), :], '适应度为：',\n",
    "            fitness[np.argmax(fitness)])\n",
    "        # 记录每代最好值，如果当代不如上一代，则替换\n",
    "        best.append(fitness[np.argmax(fitness)])\n",
    "        # if best_model_result > best[-2] or len(best_gene) == 1:\n",
    "        #     best_gene = []\n",
    "        #     for i in range(DNA_size_max):\n",
    "        #         best_gene.append(pop[np.argmax(fitness), :][i])\n",
    "        # else:\n",
    "        #     if best_model_result < best[-2] and each_generation > 0:\n",
    "        #         pop[np.argmin(fitness), :] = [i for i in best_gene]\n",
    "        #         fitness[np.argmin(fitness)] = best_model_result\n",
    "\n",
    "        # 生成新的种群\n",
    "        pop = select(pop, fitness)\n",
    "        # 复制一遍种群\n",
    "        pop_copy = pop.copy()\n",
    "        # 遍历pop中的每一个种群，进行交叉，变异，遗传操作\n",
    "        index = 0\n",
    "        for parent in pop:\n",
    "            child = crossover(parent, pop_copy)\n",
    "            child = mutate(child)\n",
    "            parent = child\n",
    "            index += 1\n",
    "\n",
    "    print(best)\n",
    "    # 需要保存的数据\n",
    "    csv1 = pd.DataFrame(best)\n",
    "    csv1 = csv1.to_csv(\"GA_\"+stock_name+\"_result.csv\")\n",
    "\n",
    "    csv2 = pd.DataFrame(pop_pop)\n",
    "    csv2 = csv2.to_csv(\"GA_\"+stock_name+\"_pop.csv\")\n",
    "\n",
    "\n",
    "for key,value in stock_list.items():\n",
    "    print (key,\"------------\",value)\n",
    "    stock_name = key\n",
    "    s_length = value\n",
    "    x_train, x_test, y_train, y_test = load_data()\n",
    "    go()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "338aba4271a224d569376385c4ef2ad191ca33f3f4abbd4c7073be9dd1fea0fe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
